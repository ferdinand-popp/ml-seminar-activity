{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "852233e2",
   "metadata": {},
   "source": [
    "# <font color=\"darkblue\">Python Activity</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a205a03",
   "metadata": {},
   "source": [
    "Within this Jupyter Notebook, there are several resources as well as guided questions for you to answer while you're going through the ML Seminar. Before starting, however, it's important that you have `pip` installed. With `pip`, you should download the following packages in your command line if you haven't done so already\n",
    "- NumPy (`pip install numpy`)\n",
    "- Pandas (`pip install pandas`)\n",
    "- Scikit-Learn (`pip install scikit-learn`)\n",
    "- Keras (`pip install keras`)\n",
    "- Plotly (option 1 for visualization) (`pip install plotly`)\n",
    "- Seaborn (optiion 2 for visualization) (`pip install seaborn`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95b324d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries before starting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ba8295",
   "metadata": {},
   "source": [
    "# <font color = \"lightblue\">1. Data Preprocessing and Feature Engineering</font>\n",
    "### Getting Started with Data Preprocessing: Pandas and NumPy\n",
    "Raw data, prior to data preprocessing, is typically not ready to be fed into any machine learning algorithm. This is because the raw data that you are provided is often incomplete, messy, noisy, and inconsistent. For example, if we were to have a `date` column, it's completely possible that ome entries within your dataframe may be inconsistent with different formatting (i.e. `dd/mm/yyyy`, `mm.dd.yyyy`, `yyyy mm-dd`). As another example, there may be missing data within your table because of unrecorded measurements or sensors not working properly. Also, there may be statistical outliers that need to be dealt with (i.e. if you're measuring the price of apartments/flat per month in Heidelberg, an outlier could be one that's 25000 EUR a month). Whatever issues your dataset has, you need to handle them accordingly, which is what data preprocessing is.\n",
    "\n",
    "Whereas data preprocessing deals with fixing your data to be a usable format, the idea of _feature engineering_ is to make better use of your pre-existing columns, which may (or may not) help your machine learning algorithm and help you develop better initial insights. For example, say that we preprocessed our aforementioned `date` column. Feature engineering would mean creating brand new columns such as `is_weekend` or `is_holiday` stemming directly from that `date` column.\n",
    "\n",
    "Typically, when using Python for data science, two of the most important packages are `pandas` and `NumPy`. `Pandas` deals primarily with dataframes and allows you to do things such as load in, manipulate, and transform your data. This framework is closely connected to `NumPy`, which is used for numerical computations within your dataframe.\n",
    "\n",
    "### Resources\n",
    "- Pandas Documentation: https://pandas.pydata.org/about/citing.html\n",
    "- In-depth Pandas Tutorials (Text/Code): https://www.geeksforgeeks.org/pandas-tutorial/?ref=lbp\n",
    "- Essential Pandas (Text/Code): https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html\n",
    "- In-depth Pandas Tutorials (Video/Code): https://www.youtube.com/playlist?list=PL-osiE80TeTsWmV9i9c58mdDCSskIFdDS\n",
    "- Pandas Cheat Sheet:\n",
    "![Pandas Cheat Sheet](./assets/pandas_cheatsheet.png)\n",
    "\n",
    "### Examples\n",
    "- Best example: https://towardsdatascience.com/30-examples-to-master-pandas-f8a2da751fa4\n",
    "- Missing values, outliers, numeric/categorical columns, interpolation: https://towardsdatascience.com/data-preprocessing-with-python-pandas-part-1-missing-data-45e76b781993\n",
    "- Missing values: https://medium.com/@arpitpathak114/data-preprocessing-with-numpy-and-pandas-5598ef69491e\n",
    "\n",
    "\n",
    "### Questions to Consider:\n",
    "- Are there any missing values or outliers within your dataset? If so, do you want to delete these rows , impute the values, or cap them to be a particular number?\n",
    "- Are there any inconsistincies within your data?\n",
    "- Have you one-hot encoded any categorical variables that you may have?\n",
    "- Are there any seemingly useless columns within your dataset?\n",
    "- Are there any duplicated rows? Duplicated columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dc431a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "602a2dff",
   "metadata": {},
   "source": [
    "# <font color = \"lightblue\">2. Exploratory Data Analysis (EDA)</font>\n",
    "\n",
    "### Getting Started with EDA: Graphing Libraries\n",
    "Within Python, there are typically two graphing libraries that are most commonly used: `Plotly` and `Seaborn`. The benefit of using `Plotly` is that it's quite interactive however `Seaborn` (which in its backend uses the graphing library `Matplotlib`) is used by more Machine Learning Engineers, Data Scientists and Bioinformaticians. Personally, I like to use `Plotly` more often for the interactiveness however, feel free to play around with both and use whichever you prefer.\n",
    "\n",
    "Getting Started with `Plotly`: https://www.youtube.com/watch?v=GGL6U0k8WYA&ab_channel=DerekBanas\n",
    "\n",
    "Getting Started with `Seaborn` and `Matplotlib`: https://www.youtube.com/watch?v=6GUZXDef2U0&ab_channel=DerekBanas\n",
    "\n",
    "Examples of `Seaborn` and their `Plotly` equivalents: https://analyticsindiamag.com/plotly-vs-seaborn-compari/\n",
    "\n",
    "### \"What's the point of EDA?\"\n",
    "DESCRIPTION OF EDA HERE.\n",
    "\n",
    "### Final Remarks\n",
    "FINAL REMARKS OF EDA HERE.\n",
    "\n",
    "### EDA Examples\n",
    "- Overview of EDA: https://www.ncbi.nlm.nih.gov/books/NBK557570/\n",
    "- Pandas EDA: https://datascientyst.com/exploratory-data-analysis-pandas-examples/\n",
    "- Best example of EDA: https://www.kaggle.com/code/pmarcelino/comprehensive-data-exploration-with-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209ed976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8a93c96",
   "metadata": {},
   "source": [
    "# <font color = \"lightblue\">3. Modeling</font>\n",
    "### Getting Started with Modeling: Scikit-Learn and Keras\n",
    "PLACEHOLDER\n",
    "\n",
    "### \"What's the point of Modeling?\"\n",
    "PLACEHOLDER\n",
    "\n",
    "### Final Remarks\n",
    "PLACEHOLDER\n",
    "\n",
    "### Modeling Resources\n",
    "- Introduction to Statistical Learning in R: https://hastie.su.domains/ISLR2/ISLRv2_website.pdf\n",
    "    - Quick Note: Although this book is based in the R coding language, this book provides <b>excellent</b> (I can't stress this enough) easy-to-understand examples while still going over some of the theory. If you'd like the Python-equivalent of these exercises, feel free to look at this: https://github.com/shilpa9a/Introduction_to_statistical_learning_summary_python\n",
    "    - Most relevant chapters:\n",
    "        - Chapter 2: Statistical Learning (must read)\n",
    "        - Chapter 3: Linear Regression\n",
    "        - Chapter 4: Classification (Logitstic Regression)\n",
    "        - Chapter 5: Resampling Methods\n",
    "            - Particularly take a look at Chapter 5.1 Cross-Validation\n",
    "        - Chapter 8: Tree-Based Methods (Decision Trees and Random Forests)\n",
    "        - Chapter 9: Support Vector Machines\n",
    "        - Chapter 10: Deep Learning\n",
    "        - Chapter 11: Survival Analysis\n",
    "        - Chapter 12: Unsupervised Learning (PCA, K-Means, and Hierarchical Clustering)\n",
    "- Introduction to Keras (Neural Networks): https://towardsdatascience.com/introduction-to-deep-learning-with-keras-17c09e4f0eb2\n",
    "- Getting Started with Keras (Neural Networks): https://machinelearningmastery.com/introduction-python-deep-learning-library-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d787d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78ffdc4b",
   "metadata": {},
   "source": [
    "# <font color = \"lightblue\">4. Results</font>\n",
    "### \"What's the point of showing results?\"\n",
    "PLACEHOLDER\n",
    "\n",
    "### Final Remarks\n",
    "PLACEHOLDER\n",
    "\n",
    "### Results Visualization Resources\n",
    "- Regression and Classifiation Metrics: https://machinelearninghd.com/sklearn-metrics-classification-regression/\n",
    "- Scikit-Learn Documentation: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "- A Data Scientist's Guide to Communicating Results: https://medium.com/comet-ml/a-data-scientists-guide-to-communicating-results-c79a5ef3e9f1\n",
    "    - Quick note: Don't need to use Comet.ml \n",
    "- Communicating Results: https://insidebigdata.com/2018/03/28/data-scientists-guide-communicating-results/\n",
    "- Great Data Science Report Example: https://www.kaggle.com/code/startupsci/titanic-data-science-solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994aadb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38e1e594",
   "metadata": {},
   "source": [
    "# <font color = \"lightblue\">5. Conclusions</font>\n",
    "### \"What's the point of a conclusions section?\"\n",
    "PLACEHOLDER\n",
    "\n",
    "### Final Remarks\n",
    "PLACEHOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6ce3a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ef3ced2",
   "metadata": {},
   "source": [
    "# <font color=\"darkblue\">Wrapping Up</font>\n",
    "PLACEHOLDER."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a7db60",
   "metadata": {},
   "source": [
    "# Sources\n",
    "1. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
