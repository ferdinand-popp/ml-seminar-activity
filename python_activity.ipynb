{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "852233e2",
   "metadata": {},
   "source": [
    "# <font color=\"darkblue\">Python Activity</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30d65cd0",
   "metadata": {},
   "source": [
    "Within this Jupyter Notebook, there are several resources as well as guided questions for you to answer while you're going through the ML Seminar. Before starting, however, it's important that you have `pip` installed. With `pip`, you should download the following packages in your command line if you haven't done so already\n",
    "- NumPy (`pip install numpy`)\n",
    "- Pandas (`pip install pandas`)\n",
    "- Scikit-Learn (`pip install scikit-learn`)\n",
    "- Keras (`pip install keras`)\n",
    "- Plotly (option 1 for visualization) (`pip install plotly`)\n",
    "- Seaborn (option 2 for visualization) (`pip install seaborn`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95b324d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries before starting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ba8295",
   "metadata": {},
   "source": [
    "# <font color = \"lightblue\">1. Data Preprocessing and Feature Engineering</font>\n",
    "### Getting Started with Data Preprocessing: Pandas and NumPy\n",
    "Raw data, prior to data preprocessing, is typically not ready to be fed into any machine learning algorithm. This is because the raw data that you are provided is often incomplete, messy, noisy, and inconsistent. For example, if we were to have a `date` column, it's completely possible that some entries within your dataframe may be inconsistent with different formatting (i.e. `dd/mm/yyyy`, `mm.dd.yyyy`, `yyyy mm-dd`). As another example, there may be missing data within your table because of unrecorded measurements or sensors not working properly. Also, there may be statistical outliers that need to be dealt with (i.e. if you're measuring the price of apartments/flat per month in Heidelberg, an outlier could be one that's 25000 EUR a month). Whatever issues your dataset has, you need to handle them accordingly, which is what data preprocessing is.\n",
    "\n",
    "Whereas data preprocessing deals with fixing your data to be a usable format, the idea of _feature engineering_ is to make better use of your pre-existing columns, which may (or may not) help your machine learning algorithm and help you develop better initial insights. For example, say that we preprocessed our aforementioned `date` column. Feature engineering would mean creating brand new columns such as `is_weekend` or `is_holiday` stemming directly from that `date` column.\n",
    "\n",
    "Typically, when using Python for data science, two of the most important packages are `pandas` and `NumPy`. `Pandas` deals primarily with dataframes and allows you to do things such as load in, manipulate, and transform your data. This framework is closely connected to `NumPy`, which is used for numerical computations within your dataframe.\n",
    "\n",
    "### Resources\n",
    "- Pandas Documentation: https://pandas.pydata.org/about/citing.html\n",
    "- Why Preprocessing? (Slideshow): https://citeseerx.ist.psu.edu/document?repid=rep1&type=pdf&doi=53fef985237ae14efddeaf202d44c35ce714d8e2\n",
    "- In-depth Pandas Tutorials (Text/Code): https://www.geeksforgeeks.org/pandas-tutorial/?ref=lbp\n",
    "- Essential Pandas (Text/Code): https://pandas.pydata.org/pandas-docs/stable/user_guide/10min.html\n",
    "- In-depth Pandas Tutorials (Video/Code): https://www.youtube.com/playlist?list=PL-osiE80TeTsWmV9i9c58mdDCSskIFdDS\n",
    "- Pandas Cheat Sheet:\n",
    "![Pandas Cheat Sheet](./assets/pandas_cheatsheet.png)\n",
    "\n",
    "### Examples\n",
    "- Best example: https://towardsdatascience.com/30-examples-to-master-pandas-f8a2da751fa4\n",
    "- Missing values, outliers, numeric/categorical columns, interpolation: https://towardsdatascience.com/data-preprocessing-with-python-pandas-part-1-missing-data-45e76b781993\n",
    "- Missing values: https://medium.com/@arpitpathak114/data-preprocessing-with-numpy-and-pandas-5598ef69491e\n",
    "\n",
    "\n",
    "### Questions to Consider:\n",
    "- Are there any missing values or outliers within your dataset? If so, do you want to delete these rows , impute the values, or cap them to be a particular number?\n",
    "- Are there any inconsistincies within your data?\n",
    "- Have you one-hot encoded any categorical variables that you may have?\n",
    "- Are there any seemingly useless columns within your dataset?\n",
    "- Are there any duplicated rows? Duplicated columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57dc431a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602a2dff",
   "metadata": {},
   "source": [
    "# <font color = \"lightblue\">2. Exploratory Data Analysis (EDA)</font>\n",
    "\n",
    "### Getting Started with EDA: Graphing Libraries\n",
    "Exploratory Data Analysis is used in order to get a better understanding of the dataset that you're working with., particularly through statistics and different plots. Often, you're not completely familiar with the dataset that you're working with and plotting things such as histograms, boxplots, barcharts, correlation matrices, etc. all help in giving you a better idea of what information you actually have. Through this, you could identify and hypothesize about different patterns or you can even come up with questions that you'd like to answer when moving on in the machine learning pipeline.\n",
    "\n",
    "Within Python, there are typically two graphing libraries that are most commonly used: `Plotly` and `Seaborn`. The benefit of using `Plotly` is that it's quite interactive however `Seaborn` (which in its backend uses the graphing library `Matplotlib`) is used by more Machine Learning Engineers, Data Scientists and Bioinformaticians. Personally, I like to use `Plotly` more often for the interactiveness but feel free to play around with both and use whichever you prefer.\n",
    "\n",
    "Getting Started with `Plotly`: https://www.youtube.com/watch?v=GGL6U0k8WYA&ab_channel=DerekBanas\n",
    "\n",
    "Getting Started with `Seaborn` and `Matplotlib`: https://www.youtube.com/watch?v=6GUZXDef2U0&ab_channel=DerekBanas\n",
    "\n",
    "Examples of `Seaborn` and their `Plotly` equivalents: https://analyticsindiamag.com/plotly-vs-seaborn-compari/\n",
    "\n",
    "\n",
    "### EDA Examples\n",
    "- Overview of EDA: https://www.ncbi.nlm.nih.gov/books/NBK557570/\n",
    "- Visualization Cheatsheet: https://towardsdatascience.com/your-ultimate-python-visualization-cheat-sheet-663318470db\n",
    "- Pandas EDA: https://datascientyst.com/exploratory-data-analysis-pandas-examples/\n",
    "- Best example of EDA: https://www.kaggle.com/code/pmarcelino/comprehensive-data-exploration-with-python\n",
    "- Different Types of Plots:\n",
    "![plots](./assets/plots.png)\n",
    "\n",
    "### Questions to Consider:\n",
    "- What hypotheses could be generated from your pre-existing data?\n",
    "- What are you trying to show when you have a certain plot? What is the main takeaway?\n",
    "- Is the type of plot that you created the best for displaying your point?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "209ed976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a93c96",
   "metadata": {},
   "source": [
    "# <font color = \"lightblue\">3. Modeling</font>\n",
    "### Getting Started with Modeling: Scikit-Learn and Keras\n",
    "The main concept of this seminar is to learn multiple different machine learning algorithms and apply them to real datasets. In order to implement this within Python, the two main libraries used are `scikit-learn` for more traditional machine learning algorithms such as linear regression, random forests, etc. and `keras` (and/or `tensorflow`) for neural networks. As an alternative to `keras`/`tensorflow`, some people also elect to use `PyTorch` as well. \n",
    "\n",
    "### Modeling Resources\n",
    "- Introduction to Statistical Learning in R: https://hastie.su.domains/ISLR2/ISLRv2_website.pdf\n",
    "    - Quick Note: Although this book is based in the R coding language, this book provides <b>excellent</b> (I can't stress this enough) easy-to-understand examples while still going over some of the theory. If you'd like the Python-equivalent of these exercises, feel free to look at this: https://github.com/shilpa9a/Introduction_to_statistical_learning_summary_python\n",
    "    - Most relevant chapters:\n",
    "        - Chapter 2: Statistical Learning (must read)\n",
    "        - Chapter 3: Linear Regression\n",
    "        - Chapter 4: Classification (Logitstic Regression)\n",
    "        - Chapter 5: Resampling Methods\n",
    "            - Particularly take a look at Chapter 5.1 Cross-Validation\n",
    "        - Chapter 8: Tree-Based Methods (Decision Trees and Random Forests)\n",
    "        - Chapter 9: Support Vector Machines\n",
    "        - Chapter 10: Deep Learning\n",
    "        - Chapter 11: Survival Analysis\n",
    "        - Chapter 12: Unsupervised Learning (PCA, K-Means, and Hierarchical Clustering)\n",
    "- Introduction to Keras (Neural Networks): https://towardsdatascience.com/introduction-to-deep-learning-with-keras-17c09e4f0eb2\n",
    "- Getting Started with Keras (Neural Networks): https://machinelearningmastery.com/introduction-python-deep-learning-library-keras/\n",
    "![ml-models](./assets/ml-models.png)\n",
    "\n",
    "### Questions to Consider:\n",
    "- Have you split your dataset into a training and testing split? Did you consider cross-validation?\n",
    "- If your dataset is imbalanced, does both your training/testing splits have relatively the same distribution?\n",
    "- Is this a classification or regression problem?\n",
    "- What algorithms will you try? Why do you think that's the proper one to choose? Are there any properties of one algorithm that you can't get from another?\n",
    "- What metric will you use? Why is this the best case? \n",
    "- What should be considered a \"good\" result?\n",
    "- Is your analysis reproducible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d787d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ffdc4b",
   "metadata": {},
   "source": [
    "# <font color = \"lightblue\">4. Results</font>\n",
    "### Getting Started with Results/Conclusions: \n",
    "After determining which model performs best, the final and often-overlooked phase is to properly communicate your results to your target audience. This should be done in the form of text, statistics and additional figures to further prove/disprove the hypothesis that you might've had. \n",
    "\n",
    "\n",
    "### Results Visualization Resources\n",
    "- Regression and Classifiation Metrics: https://machinelearninghd.com/sklearn-metrics-classification-regression/\n",
    "- Scikit-Learn Documentation: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "- A Data Scientist's Guide to Communicating Results: https://medium.com/comet-ml/a-data-scientists-guide-to-communicating-results-c79a5ef3e9f1\n",
    "    - Quick note: Don't need to use Comet.ml \n",
    "- Communicating Results: https://insidebigdata.com/2018/03/28/data-scientists-guide-communicating-results/\n",
    "- Great Data Science Report Example: https://www.kaggle.com/code/startupsci/titanic-data-science-solutions\n",
    "\n",
    "### Questions to Consider:\n",
    "- Who are you presenting this analysis to? Is it easy for them to understand?\n",
    "- What have you learned from your analysis? Is there anything that you would do or wouldn't do if given this project over again?\n",
    "- Were there any new insights? Were they any old insights that were validated/invalidated?\n",
    "- What are the consequences of your results?\n",
    "- What methods worked and didn't work? Why do you think that this was the case?\n",
    "    - Note: If something doesn't work, don't worry about it - welcome to science in general! The important to note here is to ask yourself _why_ you think something didn't work. Did you potentially make incorrect assumptions about your data? Is your data truly linear or is non-parametric? Do you have enough data to run the algorithm in the first place?\n",
    "- What are potential 'next steps' for someone (such as yourself) to follow after this project is done? Did your results lead to more questions that you can think of? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "994aadb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INSERT CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef3ced2",
   "metadata": {},
   "source": [
    "# <font color=\"darkblue\">Wrapping Up</font>\n",
    "Now that you've finished your analysis, I hope that you learned a lot from this! In our opinion, the best way to truly learn how to do something is by actually doing it so whether you got good results or not, at least you took the time to learn something new. Lastly, if you have any ideas as to what would make this Python activity better, feel free to email me at nicholas.abad@dkfz-heidelberg.de! Thank you! :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f9bec9",
   "metadata": {},
   "source": [
    "![meme](./assets/meme.jpeg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
